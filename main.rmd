---
title: "HDT2-Clustering"
author: "Grupo9"
date: "2023-02-18"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
#Nos ayuda a calcular la silueta
library(cluster)
#Nos ayuda para kmeans
library(e1071)
#Nos ayuda para los Gaussian  mixtures
library(mclust)
#Nos ayuda para realizar el plotcluster # nolint
library(fpc)
#Nos ayuda para poder determinar el número de clusters que es más óptimo
library(NbClust)
#Nos ayuda Para hacer gráficos mas amigables del clustering
library(factoextra)
#Nos ayuda para verificar si vale la pena hacer agrupamientos
library(hopkins)
#Nos ayuda a realizar el conjunto de graficos
library(GGally)
#Nos ayuda para realizar un mapa de calor y obtener una mejor visualización
library(pheatmap)
library(ggrepel)
#Preprocesamiento
datos <- read.csv("movies.csv")
#Normalizar datos
datos <- datos[complete.cases(read.csv("movies.csv")), ]
popularity <- datos[, "popularity"]
presupuesto <- datos[, "budget"]
income <- datos[, "revenue"]
duration <- datos[, "runtime"]
countVotes <- datos[, "voteCount"] # nolint
cle <- data.frame(popularity, presupuesto, income, duration, countVotes)
clusteringVar <- scale(cle) # nolint
```


### 1. Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. Describa con qué variables calculará los grupos.

Las variables que no son correctas de utilizar son aquellas definidas como categóricas. Esto se debe a que al no ser numericas como tal, no son las mas adecuadas para el análisis.
Por otro lado, las que si pueden se4r factibles para proporcionar datos analiticos correctos son todas aquellas que son numéricas para poder establecer relaciones.
<br/> 
<br/> Las varibales que se usaron para este análisis son las siguientes:
<br/> popularity: Que es el índice de popularity de la película calculado semanalmente
<br/> revenue: El ingreso de la película
<br/> runtime: La duración de la película
<br/> voteCount: El número de votos en la plataforma para la película
<br/> budget: El presupuesto para la película
<br/> 

### 2. Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency) Discuta sus resultados e impresiones. 

```{r} 
hopkins(clusteringVar)
#Matriz de distancia
datos_dist <- dist(clusteringVar)
```
Al aplicar el metodo de Hopkins podemos observar que el valor estadístico que obtenemos es de 0.999, el cual se encuentra
lejano al valor guia de 0.5. Esto significa que los datos no son aleatorios, involucrando que si es factible que estos mismos sean agurpados.  


<br/> Ahora bien usando un método gráfico/ la VAT (Visual Assessmento f cluster Tendency), se puede visualizar de la sigueinte manera:
<br/>
```{r}
knitr::opts_chunk$set(fig.width = 20, fig.height = 10)
fviz_dist(datos_dist, show_labels = FALSE)
```
<br/>
Como se puede observar si existen patrones en la grafica, tiene cualidades compartidas y por ende agrupales. 
También confirma nuevamente el resultado Hopkins.

# 3. Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando.Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que trabajará.



```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(factoextra)
library(cluster)

library(dplyr)

# Leer el archivo csv
movies <- read.csv("movies.csv")

# Seleccionar solo las variables numéricas
movies_numeric <- select_if(movies, is.numeric)

# Estandarizar las variables
movies_std <- scale(movies_numeric)

# Realizar el clustering con diferentes números de clusters
set.seed(123)
wss <- sapply(1:15, function(k){kmeans(movies_std, k, nstart=10)$tot.withinss})

# Graficar la curva del codo
ggplot(data.frame(x=1:15, y=wss), aes(x, y)) +
  geom_point() +
  geom_line() +
  labs(x = "Number of clusters", y = "Within cluster sum of squares") +
  theme_minimal()

```
Podemos observar que aproximadamente la grafica empieza a aplanarse en 5 entonces podemos decir que la cantidad de clusteres a trabajar es esta.




#4 Utilice los algoritmos k-medias y clustering jerárquico para agrupar. Compare los resultados generados por cada uno

podemos obtener k-means y clustering jerargico de la siguiente manera
```{r}
movies <- read.csv("movies.csv")
# Seleccionando unicamente los campos a usar
movies <- movies[, c("budget", "revenue", "runtime","popularity", "voteAvg", "voteCount")]
movies_norm <- scale(movies)
set.seed(123)
#k-means
kmeans_res <- kmeans(movies_norm, centers = 5)
clusters_kmeans <- kmeans_res$cluster
# Clustering gerargico
hclust_res <- hclust(dist(movies_norm), method = "complete")
clusters_hclust <- cutree(hclust_res, k = 5)

```

Con las variables clusters_kmeans y clusters_hclust, podemos hacer una comparación.

```{r}
# Creamos una tabla
table(clusters_kmeans, clusters_hclust)
library(ggplot2)
movies_plot <- data.frame(movies_norm, cluster = clusters_kmeans)
ggplot(movies_plot, aes(x = budget, y = revenue, color = factor(cluster))) + geom_point()

movies_plot <- data.frame(movies_norm, cluster = clusters_hclust)
ggplot(movies_plot, aes(x = budget, y = revenue, color = factor(cluster))) + geom_point()

```

Gracias a la comparación de datos, podemos decir que k-means es mas adecuado para datasets grandes, dado que al utilizar la distancia euclariana para calcular la simulitud de los puntos no necesitamos de una matriz completa, esto hace que sea más rápido en datasets con muchas observaciones. Otro punto importante es que el numero de clusters es definido antes de la ejecución, esto hace que sea escalable fácilmente, nos permite dividir el dataset en un gran numero de clusters. También podemos concluir que el algoritmo de clustering jeráquico es más adecuado para datasets pequeños como este, dado que es el caso opuesto a k-means respecto a su escalabilidad, ya que el numero de clusters se define después de la ejecución, además calcula la distancia entre todos los pares de puntos y genera una matriz completa de distancias, esto hace que sea demasiado costoso implementar.





#5 Determinar la calidad del agrupamiento hecho por cada algoritmo 
```{r}
library(cluster)
data(iris)
iris_data <- iris[, -5]
kmeans_result <- kmeans(iris_data, centers = 5)
wcss <- kmeans_result$tot.withinss
dbi <- data(iris_data, kmeans_result$cluster)
silhouette <- silhouette(kmeans_result$cluster, dist(iris_data))
cat("Within Cluster Sum of Squares (WCSS): ", wcss, "\n")
cat("Davies-Bouldin Index (DBI): ", dbi, "\n")
cat("Silhouette Width: ", mean(silhouette[, 3]), "\n")
```
#6 Interprete los grupos basado en el conocimiento que tiene de los datos. Recuerde investigar las medidas de tendencia central de las variables continuas y las tablas de frecuencia de las variables categóricas pertenecientes a cada grupo. Identifique hallazgos interesantes debido a las agrupaciones y describa para qué le podría servir.
```{r}
# Read data from file
datos <- read.csv("movies.csv")

datos <- datos[complete.cases(datos), ]

media <- mean(datos$budget)
cat("La media es:", media, "\n")

mediana <- median(datos$budget)
cat("La mediana es:", mediana, "\n")

moda <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
m <- moda(datos$budget)
cat("La moda es:", m, "\n")
```


```{r}

# Read data from file
datos <- read.csv("movies.csv")

datos <- datos[complete.cases(datos), ]

media <- mean(datos$runtime)
cat("La media es:", media, "\n")

mediana <- median(datos$runtime)
cat("La mediana es:", mediana, "\n")

moda <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
m <- moda(datos$runtime)
cat("La moda es:", m, "\n")

```

```{r}
# Read data from file
datos <- read.csv("movies.csv")

datos <- datos[complete.cases(datos), ]

media <- mean(datos$revenue)
cat("La media es:", media, "\n")

mediana <- median(datos$revenue)
cat("La mediana es:", mediana, "\n")

moda <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
m <- moda(datos$revenue)
cat("La moda es:", m, "\n")
```

