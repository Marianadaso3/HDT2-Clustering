---
title: "HDT2-Clustering"
author: "Grupo9"
date: "2023-02-18"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
#Nos ayuda a calcular la silueta
library(cluster)
#Nos ayuda para kmeans
library(e1071)
#Nos ayuda para los Gaussian  mixtures
library(mclust)
#Nos ayuda para realizar el plotcluster # nolint
library(fpc)
#Nos ayuda para poder determinar el número de clusters que es más óptimo
library(NbClust)
#Nos ayuda Para hacer gráficos mas amigables del clustering
library(factoextra)
#Nos ayuda para verificar si vale la pena hacer agrupamientos
library(hopkins)
#Nos ayuda a realizar el conjunto de graficos
library(GGally)
#Nos ayuda para realizar un mapa de calor y obtener una mejor visualización
library(pheatmap)
library(ggrepel)
#Preprocesamiento
datos <- read.csv("movies.csv")
#Normalizar datos
datos <- datos[complete.cases(read.csv("movies.csv")), ]
popularity <- datos[, "popularity"]
presupuesto <- datos[, "budget"]
income <- datos[, "revenue"]
duration <- datos[, "runtime"]
countVotes <- datos[, "voteCount"] # nolint
cle <- data.frame(popularity, presupuesto, income, duration, countVotes)
clusteringVar <- scale(cle) # nolint
```


### 1. Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. Describa con qué variables calculará los grupos.

Las variables que no son correctas de utilizar son aquellas definidas como categóricas. Esto se debe a que al no ser numericas como tal, no son las mas adecuadas para el análisis.
Por otro lado, las que si pueden se4r factibles para proporcionar datos analiticos correctos son todas aquellas que son numéricas para poder establecer relaciones.
<br/> 
<br/> Las varibales que se usaron para este análisis son las siguientes:
<br/> popularity: Que es el índice de popularity de la película calculado semanalmente
<br/> revenue: El ingreso de la película
<br/> runtime: La duración de la película
<br/> voteCount: El número de votos en la plataforma para la película
<br/> budget: El presupuesto para la película
<br/> 

### 2. Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency) Discuta sus resultados e impresiones. 

```{r} 
hopkins(clusteringVar)
#Matriz de distancia
datos_dist <- dist(clusteringVar)
```
Al aplicar el metodo de Hopkins podemos observar que el valor estadístico que obtenemos es de 0.999, el cual se encuentra
lejano al valor guia de 0.5. Esto significa que los datos no son aleatorios, involucrando que si es factible que estos mismos sean agurpados.  


<br/> Ahora bien usando un método gráfico/ la VAT (Visual Assessmento f cluster Tendency), se puede visualizar de la sigueinte manera:
<br/>
```{r}
knitr::opts_chunk$set(fig.width = 20, fig.height = 10)
fviz_dist(datos_dist, show_labels = FALSE)
```
<br/>
Como se puede observar si existen patrones en la grafica, tiene cualidades compartidas y por ende agrupales. 
También confirma nuevamente el resultado Hopkins.

# 3. Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando.Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que trabajará.



```{r}

library(readr)
library(dplyr)
library(ggplot2)
library(factoextra)
library(cluster)

library(dplyr)

# Leer el archivo csv
movies <- read.csv("movies.csv")

# Seleccionar solo las variables numéricas
movies_numeric <- select_if(movies, is.numeric)

# Estandarizar las variables
movies_std <- scale(movies_numeric)

# Realizar el clustering con diferentes números de clusters
set.seed(123)
wss <- sapply(1:15, function(k){kmeans(movies_std, k, nstart=10)$tot.withinss})

# Graficar la curva del codo
ggplot(data.frame(x=1:15, y=wss), aes(x, y)) +
  geom_point() +
  geom_line() +
  labs(x = "Number of clusters", y = "Within cluster sum of squares") +
  theme_minimal()

```



#4 Utilice los algoritmos k-medias y clustering jerárquico para agrupar. Compare los resultados generados por cada uno

k-means
```{r}
data <- read.csv("movies.csv")
selected_data <- data[, c("budget", "revenue", "runtime")]
scaled_data <- scale(selected_data)

kmeans_result <- kmeans(scaled_data, centers = 3)
kmeans_result$cluster
```
Clustering Jerárgico 
```{r}
data <- read.csv("movies.csv")
selected_data <- data[, c("budget", "revenue", "runtime")]
scaled_data <- scale(selected_data)

dist_matrix <- dist(scaled_data, method = "euclidean")
hc <- hclust(dist_matrix, method = "complete")
plot(hc, cex = 0.8, hang = -0.1, main = "Dendrograma de Clustering Jerárquico")


```

Determinar la calidad del agrupamiento hecho por cada algoritmo 
```{r}
library(cluster)
data(iris)
iris_data <- iris[, -5]
kmeans_result <- kmeans(iris_data, centers = 3)
wcss <- kmeans_result$tot.withinss
dbi <- data(iris_data, kmeans_result$cluster)
silhouette <- silhouette(kmeans_result$cluster, dist(iris_data))
cat("Within Cluster Sum of Squares (WCSS): ", wcss, "\n")
cat("Davies-Bouldin Index (DBI): ", dbi, "\n")
cat("Silhouette Width: ", mean(silhouette[, 3]), "\n")
```

